---
title: "Bootstrapping Objectness from Videos by Relaxed Common Fate and Visual Grouping"
collection: publications
excerpt: 'Segmenting objects in videos without any human annotation in any training stage.'
date: 2023-03-01
venue: '*IEEE/CVF Conference on Computer Vision and Pattern Recognition* (CVPR), 2023'
paper_url: 'https://arxiv.org/abs/2304.08025'
project_page_url: 'https://rcf-video.github.io'
video_url: 'https://www.youtube.com/watch?v=dyaDEvT4YkY'
demo_video_url: 'https://people.eecs.berkeley.edu/~longlian/RCF_video.html'
code_url: 'https://github.com/TonyLianLong/RCF-UnsupVideoSeg'
bibtex_url: 'https://github.com/TonyLianLong/RCF-UnsupVideoSeg#citation'
poster: rcf_poster.png
authors: '**Long Lian**, Zhirong Wu, Stella X. Yu'
citation:
cover_image: 2023-03-01-RCF-demo2.gif
---
We study learning object segmentation from unlabeled videos. Humans can easily segment moving objects without knowing what they are. The Gestalt law of common fate, i.e., what move at the same speed belong together, has inspired unsupervised object discovery based on motion segmentation. However, common fate is not a reliable indicator of objectness: Parts of an articulated / deformable object may not move at the same speed, whereas shadows / reflections of an object always move with it but are not part of it. Our insight is to bootstrap objectness by first learning image features from relaxed common fate and then refining them based on visual appearance grouping within the image itself and across images statistically. Specifically, we learn an image segmenter first in the loop of approximating optical flow with constant segment flow plus small within-segment residual flow, and then by refining it for more coherent appearance and statistical figure-ground relevance. On unsupervised video object segmentation, using only ResNet and convolutional heads, our model surpasses the state-of-the-art by absolute gains of 7/9/5% on DAVIS16 / STv2 / FBMS59 respectively, demonstrating the effectiveness of our ideas. Our code is publicly available.
